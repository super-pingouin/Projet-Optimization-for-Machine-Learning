{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f26eb4cb",
   "metadata": {},
   "source": [
    "# Project : Optimization for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff73a4c",
   "metadata": {},
   "source": [
    "### Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3e80dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9142260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code reproducibility\n",
    "def set_seed(seed=1):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d73252eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCHS = 20\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2df782",
   "metadata": {},
   "source": [
    "### Dataset Preprocessing and CNN benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db630709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, generator=g, worker_init_fn=seed_worker)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,generator=g, worker_init_fn=seed_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ec5afca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_model, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 8 * 8, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8580bb",
   "metadata": {},
   "source": [
    "### Training and testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "720db841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "    accuracy = correct / total\n",
    "    #print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f8c9417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, epochs, train_loader):\n",
    "    model.train()\n",
    "    \n",
    "    losses = []\n",
    "    acc_history = []\n",
    "    \n",
    "    #add initial loss \n",
    "    initial_loss=0\n",
    "    for inputs, targets in train_loader: \n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        initial_loss+=loss.item()\n",
    "    avg_initial_loss = initial_loss / len(train_loader)\n",
    "    losses.append(avg_initial_loss) \n",
    "\n",
    "    initial_accuracy = test(model, test_loader)\n",
    "    acc_history.append(initial_accuracy)\n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        losses.append(avg_loss)\n",
    "        \n",
    "        acc_history.append(test(model, test_loader))\n",
    "        #print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f}\")\n",
    "    return losses, acc_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3897151c",
   "metadata": {},
   "source": [
    "### Comparison of optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cca2881",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [1e-5,1e-4,1e-3,1e-2,1e-1]\n",
    "\n",
    "seeds = [0, 1, 2]\n",
    "# Optimiseurs Ã  comparer\n",
    "optimizers_dict = {\n",
    "    'Adam': lambda model, lr: optim.Adam(model.parameters(), lr=lr),\n",
    "    'RMSprop': lambda model, lr: optim.RMSprop(model.parameters(), lr=lr), #0.01\n",
    "    'AdaGrad': lambda model, lr: optim.Adagrad(model.parameters(), lr=lr), #0.01\n",
    "    'AdamW': lambda model, lr: optim.AdamW(model.parameters(), lr=lr), #0.001\n",
    "    'AmsGrad': lambda model, lr: optim.Adam(model.parameters(), lr=lr, amsgrad=True), #0.001\n",
    "    'NAdam' : lambda model, lr : optim.NAdam(model.parameters(), lr=lr), #0.002\n",
    "    'RAdam' : lambda model, lr : optim.RAdam(model.parameters(), lr=lr), #0.001\n",
    "    'SGD' : lambda model, lr : optim.SGD(model.parameters(), lr=lr), #0.001\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39b29277-5228-4849-8fb4-aa147b5c075b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd89cad4415a4ea7bdbbae17dfeba633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Testing optimizer: Adam\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3e456692014f41a6a9cb41bc217902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - LR = 1e-05\n",
      "  - LR = 0.0001\n",
      "  - LR = 0.001\n",
      "  - LR = 0.01\n",
      "  - LR = 0.1\n",
      "\n",
      ">>> Testing optimizer: RMSprop\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a8e586153f46bda01cff42f8d1b9aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - LR = 1e-05\n",
      "  - LR = 0.0001\n",
      "  - LR = 0.001\n",
      "  - LR = 0.01\n",
      "  - LR = 0.1\n",
      "\n",
      ">>> Testing optimizer: AdaGrad\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df86da82be747818ae17a1590810c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - LR = 1e-05\n",
      "  - LR = 0.0001\n",
      "  - LR = 0.001\n",
      "  - LR = 0.01\n",
      "  - LR = 0.1\n",
      "\n",
      ">>> Testing optimizer: AdamW\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "254e86b5f2b04b0ca0b3d21f62b11e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - LR = 1e-05\n",
      "  - LR = 0.0001\n",
      "  - LR = 0.001\n",
      "  - LR = 0.01\n",
      "  - LR = 0.1\n",
      "\n",
      ">>> Testing optimizer: AmsGrad\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655932e0ba6a4eeb9e43606abc066a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - LR = 1e-05\n",
      "  - LR = 0.0001\n",
      "  - LR = 0.001\n",
      "  - LR = 0.01\n",
      "  - LR = 0.1\n",
      "\n",
      ">>> Testing optimizer: NAdam\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8bfb3d41a6742548dd12e17145b9685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - LR = 1e-05\n",
      "  - LR = 0.0001\n",
      "  - LR = 0.001\n",
      "  - LR = 0.01\n",
      "  - LR = 0.1\n",
      "\n",
      ">>> Testing optimizer: RAdam\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "643fd837a5864464a50ae5b7393490b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - LR = 1e-05\n",
      "  - LR = 0.0001\n",
      "  - LR = 0.001\n",
      "  - LR = 0.01\n",
      "  - LR = 0.1\n",
      "\n",
      ">>> Testing optimizer: SGD\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f637f57d773451b94e58516db1fdd2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - LR = 1e-05\n",
      "  - LR = 0.0001\n",
      "  - LR = 0.001\n",
      "  - LR = 0.01\n",
      "  - LR = 0.1\n"
     ]
    }
   ],
   "source": [
    "results = defaultdict(dict)\n",
    "\n",
    "for opt_name, opt_fn in tqdm(optimizers_dict.items()):\n",
    "    print(f\"\\n>>> Testing optimizer: {opt_name}\")\n",
    "    for lr in tqdm(learning_rates):\n",
    "        print(f\"  - LR = {lr}\")\n",
    "\n",
    "        results[opt_name][lr] = {\n",
    "                                    'accuracies': [],\n",
    "                                    'losses': []\n",
    "                                }\n",
    "\n",
    "        for seed in seeds : \n",
    "            set_seed(seed)\n",
    "            model = CNN_model().to(DEVICE)\n",
    "            optimizer = opt_fn(model, lr)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            losses, acc_history = train(model, optimizer, criterion, EPOCHS, train_loader)\n",
    "    \n",
    "            results[opt_name][lr]['accuracies'].append(acc_history)\n",
    "            results[opt_name][lr]['losses'].append(losses)\n",
    "\n",
    "    with open(f'simple_studies/8model_20epoch_saved_loss/{opt_name}', 'wb') as f : \n",
    "        pickle.dump(results, f)\n",
    "\n",
    "\n",
    "for opt_name in results:\n",
    "    for lr in results[opt_name]:\n",
    "        accs_all_seeds = np.array(results[opt_name][lr]['accuracies'])\n",
    "        results[opt_name][lr]['mean_acc'] = accs_all_seeds.mean(axis=0)\n",
    "        results[opt_name][lr]['std_acc'] = accs_all_seeds.std(axis=0)\n",
    "\n",
    "        losses_all_seeds = np.array(results[opt_name][lr]['losses'])\n",
    "        mean_losses = losses_all_seeds.mean(axis=0)\n",
    "        std_losses = losses_all_seeds.std(axis=0)\n",
    "        results[opt_name][lr]['mean_losses'] = mean_losses\n",
    "        results[opt_name][lr]['std_losses'] = std_losses\n",
    "\n",
    "with open(f'simple_studies/8model_20epoch_saved_loss/final_losses', 'wb') as f : \n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9baedd-423e-4421-9c2f-5cbe0fa2ff54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opti",
   "language": "python",
   "name": "opti"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
